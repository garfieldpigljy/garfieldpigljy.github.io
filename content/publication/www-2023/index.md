---
title: Multiview Representation Learning from Crowdsourced Triplet Comparisons
authors:
- Xiaotian Lu
- Jiyi Li
- Koh Takeuchi
- Hisashi Kashima
date: '2023-01-01'
publishDate: '2024-02-04T16:07:06.839360Z'
publication_types:
- paper-conference
publication: '*Proceedings of the ACM Web Conference 2023*'
doi: 10.1145/3543507.3583431
abstract: 'Crowdsourcing has been used to collect data at scale in numerous fields.
  Triplet similarity comparison is a type of crowdsourcing task, in which crowd workers
  are asked the question “among three given objects, which two are more similar?”,
  which is relatively easy for humans to answer. However, the comparison can be sometimes
  based on multiple views, i.e., different independent attributes such as color and
  shape. Each view may lead to different results for the same three objects. Although
  an algorithm was proposed in prior work to produce multiview embeddings, it involves
  at least two problems: (1) the existing algorithm cannot independently predict multiview
  embeddings for a new sample, and (2) different people may prefer different views.
  In this study, we propose an end-to-end inductive deep learning framework to solve
  the multiview representation learning problem. The results show that our proposed
  method can obtain multiview embeddings of any object, in which each view corresponds
  to an independent attribute of the object. We collected two datasets from a crowdsourcing
  platform to experimentally investigate the performance of our proposed approach
  compared to conventional baseline methods.'
tags:
- Crowdsourcing
- Multiview
- Representation Learning
- Triplet
links:
- name: URL
  url: https://doi.org/10.1145/3543507.3583431
---
