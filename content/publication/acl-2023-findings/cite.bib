@inproceedings{ACL2023Findings,
 abstract = {As the core of task-oriented dialogue systems, dialogue state tracking (DST) is designed to track the dialogue state through the conversation between users and systems. Multi-domain DST has been an important challenge in which the dialogue states across multiple domains need to consider. In recent mainstream approaches, each domain and slot are aggregated and regarded as a single query feeding into attention with the dialogue history to obtain domain-slot specific representations. In this work, we propose disentangled domain-slot attention for multi-domain dialogue state tracking. The proposed approach disentangles the domain-slot specific information extraction in a flexible and context-dependent manner by separating the query about domains and slots in the attention component. Through a series of experiments on MultiWOZ 2.0 and MultiWOZ 2.4 datasets, we demonstrate that our proposed approach outperforms the standard multi-head attention with aggregated domain-slot query.},
 address = {Toronto, Canada},
 author = {Yang, Longfei  and
Li, Jiyi  and
Li, Sheng  and
Shinozaki, Takahiro},
 booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
 doi = {10.18653/v1/2023.findings-acl.304},
 editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
 month = {July},
 pages = {4928--4938},
 publisher = {Association for Computational Linguistics},
 title = {Multi-Domain Dialogue State Tracking with Disentangled Domain-Slot Attention},
 url = {https://aclanthology.org/2023.findings-acl.304},
 year = {2023}
}
